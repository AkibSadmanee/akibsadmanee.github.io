<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Publications-Akib</title>
    <link rel="stylesheet" href="static/css/style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css">

</head>
<body>
    <header>
        <nav>
            <ul>
                <li><a href="https://akibsadmanee.github.io/">Home</a></li>
                <li><a href="https://akibsadmanee.github.io/publications">Publications</a></li>
                <!-- <li><a href="#">Talks</a></li> -->
                <li><a href="https://akibsadmanee.github.io/teaching">Teaching</a></li>
                <!-- <li><a href="#">Portfolio</a></li> -->
                <li><a href="https://akibsadmanee.github.io/cv">Resume</a></li>
                <li><a href="#">Blog Posts</a></li>
                <!-- <li><a href="#">Guide</a></li> -->
            </ul>
        </nav>
    </header>

    <div class="container">
        <aside class="sidebar">
            <img src="static/images/dp.jpg" alt="Your Sidebar Name">
            <h2>Akib Sadmanee</h2>
            <p>Research Assistant</p>
            <p>Scalable Analytics and Informatics Lab (SAIL)</p>
            <ul class="sidebar-links">
                <li><a href="#"><i class="fas fa-map-marker-alt"></i> Honolulu, Hi, USA</a></li>
                <li><a href="#"><i class="fas fa-university"></i> University of Hawaiʻi at Mānoa</a></li>
                <li><a href="#"><i class="fas fa-envelope"></i> sadmanee(@t)hawaii(d0t)</d0t>edu</a></li>
                <li><a href="https://scholar.google.com/citations?user=yhwjV14AAAAJ&hl=en" target="_blank"><i class="fas fa-graduation-cap"></i> Google Scholar</a></li>
                <li><a href="https://orcid.org/0000-0002-7591-2659" target="_blank"><i class="fas fa-id-badge"></i> Orcid</a></li>
                <li><a href="https://github.com/AkibSadmanee", target="_blank"><i class="fas fa-code-branch"></i> Github</a></li>
            </ul>
        </aside>
        
        <main>
            <section class="publications">
                <h2>Publications</h2>
                <p>As of May 20 2024 - Citations: 17&emsp;|&emsp;h-index: 2</p>
                <ol>
                    <li>
                        <h3>Behavioral recommendation engine driven by only non-identifiable user data</h3>
                        <p><strong>Authors:</strong> Kishor Datta Gupta, Nafiz Sadman, <strong>Akib Sadmanee</strong>, Md Kamruzzaman Sarker, Roy George</p>
                        <p><strong>Journal:</strong> Machine Learning with Applications, 2023</p>
                        <p><strong>Abstract:</strong> Most recommendation systems utilize personal data to device personalized recommendations for users. Even though it seems favorable, security risks like data breaches are inevitable. This research proposes a novel reinforcement learning ‘approach’ to recommend users without collecting identifiable data. With only user activity on a session, our proposed method can model and track user behavior and formulate a recommendation system. We conclude that our algorithms demonstrate positive results in capturing user behavior without collecting private data of any kind from the user. The research is two folds. On one hand, we experiment using traditional reinforcement learning techniques (MDP, Q-learning), and on the other hand, we use deep reinforcement learning algorithms (DQN, DDQN, and D3QN) on a movie recommendation scenario. Interestingly, we observe that MDP and D3QN works comparatively better on movie recommendations.</p>
                        <a href="https://pdf.sciencedirectassets.com/777839/1-s2.0-S2666827022X00054/1-s2.0-S2666827022001177/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEMT%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCIG3HK5fzvK3EFBTf5nTbBSw3N0Dj1yNq2%2B7Us4MUaxzXAiAWBVZ3ETL3chEAQoxRbNoygWsky3NKJwj973LVZtBhlyqzBQg8EAUaDDA1OTAwMzU0Njg2NSIMxps6Wn4veKMISHfiKpAFmu%2BjS6DTNO%2Bj8UHlKPZgAxzYZQNvVLTRKInsboRvJPYymE8gttpn6lX0UGrCwicY9uWajUIibDOnylZkpY6pR19t7QlKu%2F9hWkVulpphEk4EoUS8tG8XTbELsozw3R1EuM0hk2h%2Fot0VQayRX7Gi2yA9cr87cuA6RNoqPVjSLmYo1%2FFH6C%2B%2B0FEql%2BGpQ1DFt4Ps9lUkEhFb5WrO%2FU6FWc%2BEJWB7xTxTgO5LdXFuoA5VvorZiomBWHuW9mvhDau%2B11klKbZ7TcKqP6UYDPjusth7g9DdhGMwkRHlgmkeotKvnBoc3s8WezYhJTjxQywR1qixIkACKjSUDbtvytr1wgRjgYYk6VtH12P435XMzdICoUVYtcm%2Fx1O3gjCk60N9UlVoKKhE%2BKU5LC3KuKFoQeU3%2FZFECGaYSKVJmD1gL1MzelE%2B6YskMd89ELz5TR93jwSzi1Idp7Ua0CFJWrwIxCGPU1WX%2F6EFmExdP6uViudvKXXRzRPN54emotSkd5U3mNPNqGLcXCvp0zfI0jmgZtHuSE08o1JUNymWFrLDlSqCmuFEhXcCPrCQWro0zJfPfoNs5e848pfWk3B3blW9p%2FmDZfhb71pT6QwTse6i5csFqNdW9jyhKjKepBLiNVtcUtLd4Dvdd6mkyPeK0VykKdSC4SimzMY0lAuNynG3YZKAmzE0oJmSywwdn%2F8M2R%2F5%2BKFphRyANcVzfRkpDuVaNiK5g9r%2Fnog7ixwgjnrAyZ98JFLAIYqRYIJMHI4rbUBa9RThymf6qkGVUE6m9BaBlFaxL7a8h77L4kWKx0XopvE54HArqERo%2FZJ7ta4bMib9BBWesOdK4onpcUKOzqkr2P27ApWhEkDU8mT%2BCY3qYa8wsqawsgY6sgEI1Xds5RerH4IIVvQKfNMjTxV4f%2FtCZJiO%2FEjoHhk9e5Y9FTC0bf13UJ3ijJBtGi1VTH50Zs4TcHL%2FJho1oBdotr%2Frh3anRwOKfP8Q%2Bd6IpvCFLz9AgHV0qtzkQu8RY6fAh6jIwafOH3gotNSBNkl6uuUtD8XSW%2F50rLyLpgayFJRRYC1%2BlT%2FPWYa9jGeXhiF5jlrKeM55AP6xeciTgvwFQw4YwqixH5ozhZRprQeG7vu6&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20240521T042417Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTY6SGTTJOA%2F20240521%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=abfbc886f7b13cf9978ae24f4e0c663bb56321e66d04a7c3072955b2424ab21e&hash=d12df2b5f94907a52297d0edf17db08ad1c50beb180cd620d9a71c85498ce07a&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S2666827022001177&tid=spdf-897b840d-8892-4a1c-ba73-81e2f833eaa0&sid=27b311397b4e7741de1975e9ff15aee36f74gxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=1311565653510402015d&rr=8871cbc3a85dc75a&cc=us" target="_blank">Read more</a>
                    </li>

                    <li>
                        <h3>Variational stacked local attention networks for diverse video captioning</h3>
                        <p><strong>Authors:</strong> Tonmoay Deb, <strong>Akib Sadmanee</strong>, Kishor Kumar Bhaumik, Amin Ahsan Ali, M Ashraful Amin, AKM Rahman</p>
                        <p><strong>Conference:</strong> Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, 2022</p>
                        <p><strong>Abstract:</strong> While describing spatio-temporal events in natural language, video captioning models mostly rely on the encoder’s latent visual representation. Recent progress on the encoder-decoder model attends encoder features mainly in linear interaction with the decoder. However, growing model complexity for visual data encourages more explicit feature interaction for fine-grained information, which is currently absent in the video captioning domain. Moreover, feature aggregations methods have been used to unveil richer visual representation, either by the concatenation or using a linear layer. Though feature sets for a video semantically overlap to some extent, these approaches result in objective mismatch and feature redundancy. In addition, diversity in captions is a fundamental component of expressing one event from several meaningful perspectives, currently missing in the temporal, i.e., video captioning domain. To this end, we propose Variational Stacked Local Attention Network (VSLAN), which exploits low-rank bilinear pooling for self-attentive feature interaction and stacking multiple video feature streams in a discount fashion. Each feature stack’s learned attributes contribute to our proposed diversity encoding module, followed by the decoding query stage to facilitate end-to-end diverse and natural captions without any explicit supervision on attributes. We evaluate VSLAN on MSVD and MSR-VTT datasets in terms of syntax and diversity. The CIDEr score of VSLAN outperforms current off-the-shelf methods by 7.8% on MSVD and 4.5% on MSR-VTT, respectively. On the same datasets, VSLAN achieves competitive results in caption diversity metrics.</p>
                        <a href="https://openaccess.thecvf.com/content/WACV2022/papers/Deb_Variational_Stacked_Local_Attention_Networks_for_Diverse_Video_Captioning_WACV_2022_paper.pdf" target="_blank">Read more</a>
                    </li>
                    
                    <li>
                        <h3>HeteroGenius: An Improvised ‘Intelligence’in Heterogeneous Graph Transformers</h3>
                        <p><strong>Authors:</strong> Nafiz Sadman, <strong>Akib Sadmanee</strong>, Kishor Datta Gupta, Roy George</p>
                        <p><strong>Conference:</strong> International Conference on Machine Learning and Applications, 2022</p>
                        <p><strong>Abstract:</strong> Heterogeneous graphs can capture pragmatic relations between entities (or nodes) better than homogeneous graphs. Heterogeneous graphs are crucial in search and classification problems and can correlate with social network graphs. However, this increases complexity and demands a clear understanding of the relationships, and rankings of the network. The ranking can take the form of various scoring-based systems, or finding the importance of the relations between two entities. In this research, we practice the use of incorporating a meta-edge definition, ‘Force’, between nodes to embed meaning to its dimensionality. We add this ‘Force’ to the Heterogeneous Graph Transformer, which we term as ‘HeteroGenius’, and experimentally demonstrate that the addition increases the overall accuracy by 2%.</p>
                        <a href="docs/HGT_ICMLA.pdf" target="_blank">Read more</a>
                    </li>

                    <li>
                        <h3>A Safer Approach to build Recommendation Systems on Unidentifiable Data</h3>
                        <p><strong>Authors:</strong> Kishor Datta Gupta, <strong>Akib Sadmanee</strong>, Nafiz Sadman</p>
                        <p><strong>Conference:</strong> Proceedings of the 14th International Conference on Agents and Artificial Intelligence, 2022</p>
                        <p><strong>Abstract:</strong> In recent years, data security has been one of the biggest concerns, and individuals have grown increasingly worried about the security of their personal information. Personalization typically necessitates the collection of individual data for analysis, exposing customers to privacy concerns. Companies create an illusion of safety to make people feel safe using a mainstream word, “encryption”. Though encryption protects personal data from an external breach, the companies can still exploit personal data collected from users as they own the encryption keys. We present a naive yet secure approach for recommending movies to consumers without collecting any personally identifiable information. Our proposed approach can assist a movie recommendation system understand user preferences using the user’s movie watch-time and watch history only. We conducted a comprehensive and comparative study on the performance of three deep reinforcement learning architectures, namely DQN, DDQN, and D3QN, on the same task. We observed that D3QN outperformed the other two architectures and achieved a precision of 0.880, recall of 0.805, and F1 score of 0.830. The results show that we can build a competitive movie recommendation system using unidentifiable data.</p>
                        <a href="https://www.scitepress.org/Papers/2022/108680/108680.pdf" target="_blank">Read more</a>
                    </li>

                    <li>
                        <h3>Intrinsic Evaluation of Bangla Word Embeddings</h3>
                        <p><strong>Authors:</strong> <strong>Akib Sadmanee</strong>, Nafiz Sadman, Md Iftekhar Tanveer, Md Ashraful Amin, Amin Ahsan Ali</p>
                        <p><strong>Conference:</strong> International Conference on Bangla Speech and Language Processing, 2019</p>
                        <p><strong>Abstract:</strong> Word embeddings are vector representations of word that allow machines to learn semantic and syntactic meanings by performing computations on them. Two wellknown embedding models are CBOW and Skipgram. Different methods proposed to evaluate the quality of embeddings are categorized into extrinsic and intrinsic evaluation methods. This paper focuses on intrinsic evaluation - the evaluation of the models on tasks, such as analogy prediction, semantic relatedness, synonym detection, antonym detection and concept categorization. We present intrinsic evaluations on Bangla word embedding created using CBOW and Skipgram models on a Bangla corpus that we built. These are trained on more than 700,000 articles consisting of more than 1.3 million unique words with different embedding dimension sizes, e.g., 300, 100, 64, and 32. We created the evaluation datasets for the abovementioned tasks and performed a comprehensive evaluation. We observe, word vectors of dimension 300, produced using Skipgram models, achieves accuracy of 51.33% for analogy prediction, a correlation of 0.62 for semantic relatedness, and accuracy of 53.85% and 9.56% for synonym and antonym detection 9.56%. Finally, for concept categorization the accuracy is 91.02%. The corpus and evaluation datasets are made publicly available for further research.</p>
                        <a href="docs/Intrinsic_Evaluation_of_Bangla_Word_Embeddings.pdf" target="_blank">Read more</a>
                    </li>
                    <!-- Add more publications here -->
                </ol>
            </section>
        </main>
    </div>
</body>
</html>
